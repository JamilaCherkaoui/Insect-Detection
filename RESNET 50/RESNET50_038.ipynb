{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vVQc3vsgJgZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HiUYZ-XYJhob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_sure_directory = '/content/drive/MyDrive/base_sure_enrish'"
      ],
      "metadata": {
        "id": "Ym-yso5sJjKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "def extract_label_from_filename(filename):\n",
        "    # Exemple : on extrait un label à partir du nom du fichier\n",
        "    # À adapter selon votre logique\n",
        "    return int(filename.split('-')[1].split('_')[0])\n",
        "\n",
        "class ImageLabelGenerator(Sequence):\n",
        "    def __init__(self, image_dir, image_filenames, batch_size=32, target_size=(300, 300), shuffle=True, augment=False):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_filenames = image_filenames\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Retourne le nombre de lots par epoch\n",
        "        return int(np.floor(len(self.image_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_filenames = self.image_filenames[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for filename in batch_filenames:\n",
        "            label = extract_label_from_filename(filename)\n",
        "            img_path = os.path.join(self.image_dir, filename)\n",
        "            image = load_img(img_path, target_size=self.target_size)\n",
        "            image = img_to_array(image)\n",
        "\n",
        "            # Appliquer la data augmentation si activée\n",
        "            if self.augment:\n",
        "                image = self.random_transform(image)\n",
        "\n",
        "            # Appliquer le prétraitement attendu par le modèle pré-entraîné\n",
        "            image = preprocess_input(image)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.image_filenames)\n",
        "\n",
        "    def random_transform(self, image):\n",
        "        # Convertir l'image en tenseur pour appliquer les transformations\n",
        "        image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "\n",
        "        # Flip horizontal aléatoire\n",
        "        if random.random() < 0.5:\n",
        "            image_tensor = tf.image.flip_left_right(image_tensor)\n",
        "\n",
        "        # Variation de luminosité aléatoire\n",
        "        image_tensor = tf.image.random_brightness(image_tensor, max_delta=0.1)\n",
        "\n",
        "        # Variation de contraste aléatoire\n",
        "        image_tensor = tf.image.random_contrast(image_tensor, lower=0.8, upper=1.2)\n",
        "\n",
        "        # Rotation aléatoire entre -20° et +20° via la couche RandomRotation\n",
        "        rotation_layer = tf.keras.layers.RandomRotation(factor=20/360, fill_mode='reflect')\n",
        "        image_tensor = rotation_layer(tf.expand_dims(image_tensor, axis=0))[0]\n",
        "\n",
        "        # Zoom aléatoire :\n",
        "        # On choisit un facteur entre 0.8 et 1.0, on recadre puis redimensionne à la taille originale\n",
        "        scale = random.uniform(0.8, 1.0)\n",
        "        h, w, c = image_tensor.shape\n",
        "        new_h = tf.cast(scale * h, tf.int32)\n",
        "        new_w = tf.cast(scale * w, tf.int32)\n",
        "        image_tensor = tf.image.random_crop(image_tensor, size=[new_h, new_w, c])\n",
        "        image_tensor = tf.image.resize(image_tensor, [h, w])\n",
        "\n",
        "        return image_tensor.numpy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V2Qk9gWvJje5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = [f for f in os.listdir(base_sure_directory) if f.endswith('.jpg')]\n",
        "\n",
        "train_files, val_files = train_test_split(all_images, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "train_generator = ImageLabelGenerator(base_sure_directory, train_files, batch_size=32, augment=True)\n",
        "val_generator = ImageLabelGenerator(base_sure_directory, val_files, batch_size=32, shuffle=False, augment=False)"
      ],
      "metadata": {
        "id": "2gqX1Ar2JoKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWxjMH62JFzm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# =========================\n",
        "# 1) Paramètres & Générateurs\n",
        "# =========================\n",
        "IMG_HEIGHT = 300\n",
        "IMG_WIDTH = 300\n",
        "NUM_CLASSES = 9\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Supposons que train_generator et val_generator soient déjà définis\n",
        "# et qu'ils appliquent un prétraitement compatible ResNet (par ex. tf.keras.applications.resnet50.preprocess_input).\n",
        "# Sinon, assurez-vous de l'ajouter dans votre code de génération.\n",
        "\n",
        "# =========================\n",
        "# 2) Construction du modèle\n",
        "# =========================\n",
        "# Charger ResNet50 pré-entraîné sur ImageNet, sans la tête fully-connected\n",
        "base_model = ResNet50(\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Phase 1 : geler toutes les couches du ResNet\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Construction de la tête de classification\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)  # Dropout modéré\n",
        "x = layers.Dense(\n",
        "    128,\n",
        "    activation='relu',\n",
        "    kernel_regularizer=regularizers.l2(1e-5)\n",
        ")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# =========================\n",
        "# 3) Phase 1 : Entraîner la tête\n",
        "# =========================\n",
        "# On choisit un LR plutôt modéré (ex: 1e-4)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "checkpoint_phase1 = ModelCheckpoint(\n",
        "    \"best_phase1.h5\",\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "\n",
        "history_phase1 = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15,  # Ajustez selon la taille de votre dataset\n",
        "    callbacks=[checkpoint_phase1, early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# Recharger les meilleurs poids de la Phase 1\n",
        "model.load_weights(\"best_phase1.h5\")\n",
        "\n",
        "# =========================\n",
        "# 4) Phase 2 : Fine-tuning\n",
        "# =========================\n",
        "# Débloquer, par exemple, les 50 dernières couches du ResNet50\n",
        "for layer in base_model.layers[-50:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompiler avec un LR plus faible pour affiner les couches dégélées\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "checkpoint_phase2 = ModelCheckpoint(\n",
        "    \"best_phase2.h5\",\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stop_2 = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr_2 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "\n",
        "history_phase2 = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=80,  # Ajustez selon vos besoins\n",
        "    callbacks=[checkpoint_phase2, early_stop_2, reduce_lr_2]\n",
        ")\n",
        "\n",
        "# Recharger le meilleur modèle obtenu en Phase 2 (optionnel)\n",
        "model.load_weights(\"best_phase2.h5\")\n",
        "\n",
        "# =========================\n",
        "# 5) Évaluation finale\n",
        "# =========================\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(\"Validation accuracy finale :\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6) Affichage des courbes\n",
        "# =========================\n",
        "# 1. Récupérer et concaténer les métriques Phase 1 + Phase 2\n",
        "train_loss = history_phase1.history['loss'] + history_phase2.history['loss']\n",
        "val_loss   = history_phase1.history['val_loss'] + history_phase2.history['val_loss']\n",
        "\n",
        "train_acc  = history_phase1.history['accuracy'] + history_phase2.history['accuracy']\n",
        "val_acc    = history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy']\n",
        "\n",
        "# 2. Tracer la Loss (Train + Val)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Courbe de Loss (Phase 1 + Phase 2)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 3. Tracer l’Accuracy (Train + Val)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Courbe d’Accuracy (Phase 1 + Phase 2)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZnHJvzn0JvBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}