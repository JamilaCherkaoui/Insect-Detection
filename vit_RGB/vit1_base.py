# -*- coding: utf-8 -*-
"""vit1_SAUVEGUARDE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BGH3nf33XsdN9t5Vs47MxYKsVY5wyOSN
"""

import tensorflow as tf
import os
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.python.keras.models import Model
from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Input, GlobalAveragePooling1D, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import Sequence
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
import random
os.environ["CUDA_VISIBLE_DEVICES"]= "1"

def extract_label_from_filename(filename):
    parts = filename.split("-")
    if len(parts) < 2:
        return -1
    label_token = parts[1]
    token_parts = label_token.split("_")
    try:
        return int(token_parts[0])
    except ValueError:
        return -1

class ImageLabelGenerator(Sequence):
    def __init__(self, image_paths, batch_size=32, target_size=(768,768), shuffle=True, augment=False):
        self.image_paths = image_paths
        self.batch_size = batch_size
        self.target_size = target_size
        self.shuffle = shuffle
        self.augment = augment
        if self.augment:
            self.augmentor = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')
        else:
            self.augmentor = None
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.image_paths) / self.batch_size))

    def __getitem__(self, index):
        batch_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]
        images = []
        labels = []
        for path in batch_paths:
            filename = os.path.basename(path)
            label = extract_label_from_filename(filename)
            try:
                img = load_img(path, target_size=self.target_size, color_mode='rgb')
                img_array = img_to_array(img)
                if self.augmentor is not None:
                    img_array = self.augmentor.random_transform(img_array)
            except:
                continue
            images.append(img_array)
            labels.append(label)

        if len(images) == 0:
            return np.empty((0, *self.target_size, 3)), np.empty((0,))

        images_array = np.array(images)
        labels_array = np.array(labels)


        return images_array, labels_array

    def on_epoch_end(self):
        if self.shuffle:
            random.shuffle(self.image_paths)

full_base_directory = '/home/barrage/groupe2/base_train_complete'
images = [os.path.join(full_base_directory, f) for f in os.listdir(full_base_directory) if f.endswith('.jpg')]
train_files, val_files = train_test_split(images, test_size=0.2, random_state=42, shuffle=True)
train_generator = ImageLabelGenerator(train_files, batch_size=8, target_size=(512,512), augment=True)
val_generator = ImageLabelGenerator(val_files, batch_size=8, target_size=(512,512), shuffle=False, augment=False)

class PatchEmbedding(tf.keras.layers.Layer):
    def __init__(self, patch_size=32, embed_dim=512, **kwargs):
        super().__init__(**kwargs)
        self.patch_size = patch_size
        self.num_patch = 32*32
        self.position_embedding = tf.keras.layers.Embedding(self.num_patch, embed_dim)

        self.embed_dim = embed_dim
        self.proj = tf.keras.layers.Conv2D(
            filters=embed_dim,
            kernel_size=patch_size,
            strides=patch_size,
            padding='valid'
        )

    def call(self, x):
        x = self.proj(x)
        bsz = tf.shape(x)[0]

        num_patches = tf.shape(x)[1] * tf.shape(x)[2]
        x = tf.reshape(x, (bsz, num_patches, self.embed_dim))
        position = tf.range(0, tf.shape(x)[1])
        position_embedding = self.position_embedding(position)
        return x + position_embedding

class block_transformer(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.denseQ = Dense(512, activation="linear")
        self.denseK = Dense(512, activation="linear")
        self.denseV = Dense(512, activation="linear")
        self.num_heads = 8
        self.norm1 = tf.keras.layers.LayerNormalization()
        self.norm2 = tf.keras.layers.LayerNormalization()
        self.mlp1 = Dense(512, activation="gelu")
        self.mlp2 = Dense(512, activation="gelu")
        self.proj = Dense(512)
        self.dropout = Dropout(0.2)

    def call(self, x):
        x_nrom = self.norm1(x)
        b = tf.shape(x_nrom)[0]
        n = tf.shape(x_nrom)[1]
        c = tf.shape(x_nrom)[2]
        q = self.denseQ(x_nrom)
        q = tf.reshape(q, (b, n, 1, self.num_heads, c // self.num_heads))
        q = tf.transpose(q, perm=[2, 0, 3, 1, 4])
        k = self.denseK(x_nrom)
        k = tf.reshape(k, (b, n, 1, self.num_heads, c // self.num_heads))
        k = tf.transpose(k, perm=[2, 0, 3, 1, 4])
        v = self.denseV(x_nrom)
        v = tf.reshape(v, (b, n, 1, self.num_heads, c // self.num_heads))
        v = tf.transpose(v, perm=[2, 0, 3, 1, 4])
        q = q[0]
        k = k[0]
        v = v[0]
        attn = tf.matmul(q, k, transpose_b=True)
        attn = tf.nn.softmax(attn, axis=-1)
        y = tf.matmul(attn, v)
        y = tf.transpose(y, perm=[0, 2, 1, 3])
        y = tf.reshape(y, (b, n, c))
        y = self.proj(y)
        x = x + y
        x_norm = self.norm2(x)
        y = self.mlp1(x_norm)
        y = self.dropout(y)
        y = self.mlp2(y)
        y = self.dropout(y)
        x = x + y
        return x, attn

class Classifier(tf.keras.Model):
    def __init__(self, num_class, patch_size=16, embed_dim=512):
        super().__init__()
        self.patch_embed = PatchEmbedding(patch_size=patch_size, embed_dim=embed_dim)
        self.block1 = block_transformer()
        self.block2 = block_transformer()
        self.block3 = block_transformer()
        self.block4 = block_transformer()
        self.block5 = block_transformer()
        self.block6 = block_transformer()
        self.global_pool = tf.keras.layers.GlobalAveragePooling1D()
        self.dense1 = Dense(512, activation="relu")
        self.dense2 = Dense(512, activation="relu")
        self.dense3 = Dense(256, activation="relu")
        self.dense4 = Dense(256, activation="relu")
        self.outl = Dense(num_class, activation="softmax")

    def call(self, x):
        x = self.patch_embed(x)
        x, a1 = self.block1(x)
        x, a2 = self.block2(x)
        x, a3 = self.block3(x)
        x, a4 = self.block4(x)
        x, a5 = self.block5(x)
        x, a6 = self.block6(x)
        x = self.global_pool(x)
        x = self.dense1(x)
        x = self.dense2(x)
        x = self.dense3(x)
        x = self.dense4(x)
        out = self.outl(x)
        return out, [a1, a2, a3, a4, a5, a6]

model = Classifier(9)
model(np.random.random((1, 512, 512, 3)))
optimizer = Adam(learning_rate=1e-5)

class ClassifierWrapper(tf.keras.Model):
    def __init__(self, classifier):
        super().__init__()
        self.classifier = classifier

    def call(self, x, training=False):
        logits, attn = self.classifier(x, training=training)
        return logits

wrapped_model = ClassifierWrapper(model)
wrapped_model(np.random.random((1, 512, 512, 3)))
tf.keras.mixed_precision.set_global_policy('mixed_float16')
wrapped_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

history = wrapped_model.fit(train_generator, validation_data=val_generator, epochs=100, callbacks=[reduce_lr])
save_path = '/home/barrage/groupe2/wrapped_model_discriminator.weights.h5'
wrapped_model.save_weights(save_path)
print(save_path)